{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdA4KjrNwn5B",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ELE6310 - Assignment 1 - Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm4CU_e6xHpL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Name: \n",
    "#### Student ID: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HGmDZ11LULkF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title Mount your Google Drive\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DF9zCVJULkH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title Link your assignment folder & install requirements\n",
    "#@markdown Enter the path to the assignment folder in your Google Drive\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "folder = \"/content/gdrive/MyDrive/ELE6310/A1\" #@param {type:\"string\"}\n",
    "!ln -Ts $folder /content/A1 2> /dev/null\n",
    "\n",
    "# Add the assignment folder to Python path\n",
    "if '/content/A1' not in sys.path:\n",
    "    sys.path.insert(0, '/content/A1')\n",
    "\n",
    "# Install requirements\n",
    "!pip install -qr /content/A1/requirements.txt\n",
    "\n",
    "# Check if CUDA is available\n",
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "    warnings.warn('CUDA is not available.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GnYxJmVqyj6a",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1- Calibration [30 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcJ0NuyOoZ4p",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import solution\n",
    "from common.test_functions import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8R6Y-rcbVuMG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* First, complete `linear_quantize`, `linear_dequantize`, `update_scale_and_zero_point`, and `get_scale` functions  in `solution.py`and then run the below tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Usu5pr3cVUX0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_linear_quantize()\n",
    "test_linear_dequantize()\n",
    "test_reset_scale_and_zero_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moxo1oHfWVXk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Now we will see the performance of each quantization method on there different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHHh5KEolgvc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = torch.load(os.path.join(folder,'Dataset_A.t')) \n",
    "plot_real_dequantized_histogram(data, N_bits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxPGGyqJlgvd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = torch.load(os.path.join(folder,'Dataset_B.t'))\n",
    "plot_real_dequantized_histogram(data, N_bits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaDHpDHQ3bWG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Compare your results. Which method works better? Do you think the quantiztion error has a bias? explain your observation.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HnK3c81SknhI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\\begin{array}{|c|ccc|ccc|}\\hline\\\\ \n",
    "     Dataset && A &&& B \\\\ \\hline\n",
    "Bit width & 8 & 4 & 2 & 8 & 4 & 2 \\\\ \\hline\n",
    "Symmetric & ?? & ?? & ?? & ?? & ?? & ?? \\\\ \n",
    "Asymmetric & ?? & ?? & ?? & ?? & ?? & ?? \\\\ \n",
    "Heuristic Method & ?? & ?? & ?? & ?? & ?? & ?? \\\\ \n",
    "SAWB & ?? & ?? & ?? & ?? & ?? & ?? \\\\ \\hline\n",
    "\\end{array}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VpegJgT9RVvG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2- PTQ -vs- QTA [30 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUDro-oYXJL3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Complete `quantize_func_STE` in order to the quantization block (linear quantize and dequntize together) to meet the STE condition.\n",
    "\n",
    "\n",
    "* Complete `quantized_linear_function` and `quantized_conv2d_function` function only using `integer_linear` and `integer_conv2d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOdnoeBamS0w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_STE_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfwlhUbqlgve",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_quantized_linear_function(weight_N_bits=2, act_N_bits=8, method='SAWB', bias=False)\n",
    "test_quantized_linear_module(weight_N_bits=8, act_N_bits=8, method='sym', bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23nKTFn-lgve",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_quantized_conv2d_function(weight_N_bits=2, act_N_bits=2, method='sym', bias=False)\n",
    "test_quantized_conv2d_module(weight_N_bits=8, act_N_bits=8, method='SAWB', bias=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "31MbpcH2S7cf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* In this assignment we use resnet32 with pre-trained weights on CIFAR10. First, Let's see the accuracy and model size of our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HYspOWxw29A",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from common.utils import load_CIFAR10_dataset, evaluate, fit, model_size\n",
    "from common.resnet import resnet32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGCwFFPmlgve",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Seed = 6310\n",
    "torch.manual_seed(Seed)\n",
    "np.random.seed(Seed)\n",
    "random.seed(Seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(Seed)\n",
    "    torch.cuda.manual_seed_all(Seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqkaY-CWaXR3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader, calibration_loader = load_CIFAR10_dataset(batch_size=256, calibration_batch_size=1024)\n",
    "model = resnet32(pretrained=True, save_path='./save/')\n",
    "device = torch.device('cuda:0')\n",
    "model.to(device)\n",
    "\n",
    "accuracy = evaluate(model, test_loader, device)\n",
    "print(\"test accuracy of fp model:\", accuracy)\n",
    "model_size(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N36zX5HacnPA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* In the first step, we use calibration set to initial scale factors of the activation in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhAc13r8ckCc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "method='sym'\n",
    "act_N_bits=4\n",
    "weight_N_bits=4\n",
    "quantized_model = model_to_quant(model, calibration_loader, act_N_bits, weight_N_bits,method, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xJKTr4Ilgvf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate(quantized_model, test_loader, device)\n",
    "print(\"test accuracy of fp model:\", accuracy)\n",
    "model_size(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9xPNaD_lgvf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_layers_histogram(quantized_model)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aH4Cx3aVrufE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Try `W8A8`, `W4A4`, `W2A2`, `W4A2`, and `W2A4` quantization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlIvyJ_locDq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Now try to fine-tune the specified models using any desired training method, and save the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ksx4EKcoYqh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(quantized_model.parameters(), 1e-4, momentum=0.9, weight_decay=0.0005, nesterov=True)\n",
    "scheduler = None\n",
    "\n",
    "train_accuracy, test_accuracy = fit(quantized_model, 5, train_loader, test_loader, criterion, optimizer, scheduler, device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NCF0o0HMpDob",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3- Variable precision [20 pts]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "A5ZoLeeFXUSm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the  Variable precision (or \"Mixed-precision\") method, each layer is quantized with different bit precision. In this part, we want to find the optimal model-size for the resnet32 on the CIFAR-10 dataset. For this part, we only focus on weight quantization (with signed symmetric method) and we keep the activation in 16 bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCUcFhgVU3vE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Use a method of your choice to find the optimal model size with a constraint on test accuracy above 85\\%. \n",
    "Any reasonable attempt at exploring the design space will give you full marks. Better approaches/results will be considered for bonus points. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IlXvpO7C_px5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\\begin{array}{|c|cc|cc|}\\hline\\\\ \n",
    "      & PTQ && QAT \\\\ \\hline\n",
    "method & Symmetric & SAWB & Symmetric & SAWB \\\\ \\hline\n",
    "W8A8 & ?? & ?? & ?? & ?? \\\\ \n",
    "W4A4 & ?? & ?? & ?? & ?? \\\\ \n",
    "W2A2 & ?? & ?? & ?? & ?? \\\\ \n",
    "W4A2 & ?? & ?? & ?? & ?? \\\\ \n",
    "W2A4 & ?? & ?? & ?? & ?? \\\\ \\hline\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2LObcz_mlgvf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bitwidth_dict = {\n",
    "    'layer1.0.conv1': 8,\n",
    "    'layer1.0.conv2': 8,\n",
    "    'layer1.1.conv1': 8,\n",
    "    'layer1.1.conv2': 8,\n",
    "    'layer1.2.conv1': 8,\n",
    "    'layer1.2.conv2': 8,\n",
    "    'layer1.3.conv1': 8,\n",
    "    'layer1.3.conv2': 8,\n",
    "    'layer1.4.conv1': 8,\n",
    "    'layer1.4.conv2': 8,\n",
    "\n",
    "    'layer2.0.conv1': 8,\n",
    "    'layer2.0.conv2': 8,\n",
    "    'layer2.0.downsample.0': 8,\n",
    "    'layer2.1.conv1': 8,\n",
    "    'layer2.1.conv2': 8,\n",
    "    'layer2.2.conv1': 8,\n",
    "    'layer2.2.conv2': 8,\n",
    "    'layer2.3.conv1': 8,\n",
    "    'layer2.3.conv2': 8,\n",
    "    'layer2.4.conv1': 8,\n",
    "    'layer2.4.conv2': 8,\n",
    "\n",
    "    'layer3.0.conv1': 8,\n",
    "    'layer3.0.conv2': 8,\n",
    "    'layer3.0.downsample.0': 8,\n",
    "    'layer3.1.conv1': 8,\n",
    "    'layer3.1.conv2': 8,\n",
    "    'layer3.2.conv1': 8,\n",
    "    'layer3.2.conv2': 8,\n",
    "    'layer3.3.conv1': 8,\n",
    "    'layer3.3.conv2': 8,\n",
    "    'layer3.4.conv1': 8,\n",
    "    'layer3.4.conv2': 8,\n",
    "\n",
    "    'fc': 2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_DTblJwlgvf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "method='sym'\n",
    "act_N_bits=16\n",
    "quantized_model = model_to_quant(model, calibration_loader, act_N_bits, weight_N_bits,method, device, bitwidth_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfoimdbXlgvg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate(quantized_model, test_loader, device)\n",
    "print(\"test accuracy of fp model:\", accuracy)\n",
    "model_size(quantized_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Huffman coding [20 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/r17bensa/Documents/these/ELE6310E/A1/main.ipynb Cell 38\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/r17bensa/Documents/these/ELE6310E/A1/main.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mresnet_quant\u001b[39;00m \u001b[39mimport\u001b[39;00m resnet32_quant\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/r17bensa/Documents/these/ELE6310E/A1/main.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_quant \u001b[39m=\u001b[39m resnet32_quant(pretrained\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/r17bensa/Documents/these/ELE6310E/A1/main.ipynb#X51sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#load the weights you uploaded\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/these/ELE6310E/A1/common/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresnet\u001b[39;00m \u001b[39mimport\u001b[39;00m resnet32\n\u001b[1;32m      2\u001b[0m from\u001b[39m.\u001b[39mresnet_quant \u001b[39mimport\u001b[39;00m \u001b[39mresnet32_quant\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/these/ELE6310E/A1/common/resnet.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mModified from https://github.com/chenyaofo/pytorch-cifar-models\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msolution\u001b[39;00m \u001b[39mimport\u001b[39;00m Quantized_Linear, Quantized_Conv2d\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/these/ELE6310E/A1/solution.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/__init__.py:1465\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m library\n\u001b[1;32m   1464\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m-> 1465\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _meta_registrations\n\u001b[1;32m   1467\u001b[0m \u001b[39m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[1;32m   1468\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mTORCH_CUDA_SANITIZER\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_meta_registrations.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims_common\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mutils\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_decomp\u001b[39;00m \u001b[39mimport\u001b[39;00m _add_op_to_registry, global_decomposition_table, meta_table\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m OpOverload\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims\u001b[39;00m \u001b[39mimport\u001b[39;00m _elementwise_meta, ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_decomp/__init__.py:170\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39m# populate the table\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_decomp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecompositions\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_refs\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# This list was copied from torch/_inductor/decomposition.py\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[39m# excluding decompositions that results in prim ops\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39m# Resulting opset of decomposition is core aten ops\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcore_aten_decompositions\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[OpOverload, Callable]:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_refs/__init__.py:2282\u001b[0m\n\u001b[1;32m   2276\u001b[0m         dim \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2277\u001b[0m     \u001b[39mreturn\u001b[39;00m dim, unbiased\n\u001b[1;32m   2280\u001b[0m \u001b[39m@register_decomposition\u001b[39;49m(aten\u001b[39m.\u001b[39;49mvar)\n\u001b[1;32m   2281\u001b[0m \u001b[39m@out_wrapper\u001b[39;49m()\n\u001b[0;32m-> 2282\u001b[0m \u001b[39mdef\u001b[39;49;00m \u001b[39mvar\u001b[39;49m(\n\u001b[1;32m   2283\u001b[0m     a: TensorLikeType,\n\u001b[1;32m   2284\u001b[0m     dim: Optional[DimsType] \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2285\u001b[0m     unbiased: Optional[\u001b[39mbool\u001b[39;49m] \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2286\u001b[0m     keepdim: \u001b[39mbool\u001b[39;49m \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   2287\u001b[0m     \u001b[39m*\u001b[39;49m,\n\u001b[1;32m   2288\u001b[0m     correction: Optional[\u001b[39mint\u001b[39;49m] \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2289\u001b[0m ) \u001b[39m-\u001b[39;49m\u001b[39m>\u001b[39;49m TensorLikeType:\n\u001b[1;32m   2290\u001b[0m     dim, unbiased \u001b[39m=\u001b[39;49m _dim_var_dispatch(dim, unbiased)\n\u001b[1;32m   2291\u001b[0m     correction \u001b[39m=\u001b[39;49m utils\u001b[39m.\u001b[39;49mset_correction(unbiased, correction)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_decomp/__init__.py:131\u001b[0m, in \u001b[0;36mregister_decomposition.<locals>.decomposition_decorator\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    128\u001b[0m     _add_op_to_registry(registry, op, fn)\n\u001b[1;32m    130\u001b[0m \u001b[39m# To handle allowing multiple aten_ops at once\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m tree_map(register, aten_op)\n\u001b[1;32m    132\u001b[0m \u001b[39mreturn\u001b[39;00m fn\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:196\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(fn, pytree)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtree_map\u001b[39m(fn: Any, pytree: PyTree) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PyTree:\n\u001b[1;32m    195\u001b[0m     flat_args, spec \u001b[39m=\u001b[39m tree_flatten(pytree)\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mreturn\u001b[39;00m tree_unflatten([fn(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m flat_args], spec)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:196\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtree_map\u001b[39m(fn: Any, pytree: PyTree) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PyTree:\n\u001b[1;32m    195\u001b[0m     flat_args, spec \u001b[39m=\u001b[39m tree_flatten(pytree)\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mreturn\u001b[39;00m tree_unflatten([fn(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m flat_args], spec)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_decomp/__init__.py:128\u001b[0m, in \u001b[0;36mregister_decomposition.<locals>.decomposition_decorator.<locals>.register\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregister\u001b[39m(op):\n\u001b[0;32m--> 128\u001b[0m     _add_op_to_registry(registry, op, fn)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_decomp/__init__.py:53\u001b[0m, in \u001b[0;36m_add_op_to_registry\u001b[0;34m(registry, op, fn)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mduplicate registrations for \u001b[39m\u001b[39m{\u001b[39;00mop_overload\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[39m# TorchScript dumps a bunch of extra nonsense overloads\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m# which don't have corresponding dispatcher entries, we need\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39m# to filter those out, e.g aten.add.float_int\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_dispatch_has_kernel(op_overload\u001b[39m.\u001b[39;49mname()):\n\u001b[1;32m     54\u001b[0m     registry[op_overload] \u001b[39m=\u001b[39m fn\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from common.resnet_quant import resnet32_quant\n",
    "\n",
    "model_quant = resnet32_quant(pretrained=False)\n",
    "#load the weights you uploaded\n",
    "model_quant.load_state_dict(torch.load(\"resnet32_qw2.pth\"))\n",
    "device = torch.device('cuda:0')\n",
    "model_quant.to(device)\n",
    "\n",
    "\n",
    "#Convolutional weight you need to encode\n",
    "conv_weight = model_quant.layer3[2].conv2.int_weight()\n",
    "#fully connected layer weight you need to encode\n",
    "fc_weight = model_quant.fc.int_weight()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
